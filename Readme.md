# ğŸš€ Kasparro Backend Assignment

A backend service built using **FastAPI**, **PostgreSQL**, and **Docker** that ingests cryptocurrency data from multiple sources, normalizes it, and exposes REST APIs for querying and monitoring ingestion statistics.

---

## ğŸ“Œ Features

* FastAPI-based REST backend
* PostgreSQL database
* Data ingestion from:

  * CoinPaprika public API
  * CSV file
* Normalized crypto asset storage
* Raw data tracking
* ETL checkpoint tracking
* Dockerized setup (API + DB)
* Swagger/OpenAPI documentation
* Health and monitoring endpoints

---

## ğŸ›  Tech Stack

* **Backend:** FastAPI
* **Database:** PostgreSQL
* **ORM:** SQLAlchemy
* **Data Ingestion:** Requests, CSV
* **Containerization:** Docker & Docker Compose
* **Testing:** Pytest
* **API Docs:** Swagger (OpenAPI)

---

## ğŸ“‚ Project Structure

```
.
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py          # FastAPI app & routes
â”‚   â”œâ”€â”€ db.py            # Database connection
â”‚   â”œâ”€â”€ schemas.py       # SQLAlchemy models
â”‚   â”œâ”€â”€ ingestion.py     # ETL logic (API + CSV)
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ crypto_prices.csv
â”‚
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ test_api.py
â”‚
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ Makefile
â””â”€â”€ README.md
```

---

## âš™ï¸ Environment Variables

Create a `.env` file in the root directory:

```env
DATABASE_URL=postgresql://kasparro:kasparro@db:5432/kasparro_db
```

---

## ğŸ³ Running with Docker (Recommended)

### 1ï¸âƒ£ Build & Start Services

```bash
docker compose up --build
```

### 2ï¸âƒ£ API will be available at

* **API Base URL:** `http://localhost:8000`
* **Swagger Docs:** `http://localhost:8000/docs`

---

## ğŸ“¡ API Endpoints

### âœ… Health Check

```
GET /health
```

Response:

```json
{
  "status": "ok",
  "database": "connected",
  "timestamp": 123456789,
  "request_id": "uuid"
}
```

---

### ğŸ“Š Get Crypto Data

```
GET /data?limit=10&offset=0
```

Response:

```json
{
  "request_id": "uuid",
  "api_latency_ms": 12,
  "count": 10,
  "data": [
    {
      "symbol": "BTC",
      "name": "Bitcoin",
      "price_usd": 88000,
      "source": "coinpaprika"
    }
  ]
}
```

---

### ğŸ“ˆ Ingestion Stats

```
GET /stats
```

Response:

```json
{
  "raw_records": 68,
  "normalized_records": 10,
  "sources": [
    {
      "source": "csv",
      "last_run": "2025-12-25T07:11:06Z"
    }
  ]
}
```

---

## ğŸ”„ Data Ingestion Flow

* Runs automatically on application startup
* Steps:

  1. Fetch data from CoinPaprika API
  2. Load CSV data
  3. Store raw payloads
  4. Normalize into `crypto_assets`
  5. Update ETL checkpoints

---

## ğŸ§ª Running Tests

```bash
pytest
```

---

## ğŸ§  Design Notes

* Separation of concerns (API, DB, ETL)
* Docker-first approach for consistency
* Simple schema for clarity and performance
* Swagger enabled for easy API testing

---

## âœ… Assignment Status

âœ” All required features implemented
âœ” Dockerized and reproducible
âœ” APIs functional and documented
âœ” Ready for evaluation

---

## ğŸ‘¤ Author

**Khushi Gupta**
Final Year Engineering Student
Backend Assignment Submissionpwd
